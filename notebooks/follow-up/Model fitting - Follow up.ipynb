{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting - Follow-up Sample\n",
    "\n",
    "## Analysis overview\n",
    "\n",
    "#### Discovery sample\n",
    "\n",
    "1. Model fitting: [`Model fitting - Discovery.ipynb`](<../../notebooks/discovery/Model fitting - Discovery.ipynb>)\n",
    "2. Confidence analysis: [`Confidence analysis - Discovery.ipynb`](<../../notebooks/discovery/Confidence analysis - Discovery.ipynb>)\n",
    "3. Transdiagnostic factor estimation: [`Transdiagnostic factors - Discovery.ipynb`](<../../notebooks/discovery/Transdiagnostic factors - Discovery.ipynb>)\n",
    "4. Symptom-behaviour analyses: [`Symptom analyses - Discovery.ipynb`](<../../notebooks/discovery/Symptom analyses - Discovery.ipynb>)\n",
    "\n",
    "#### Replication sample\n",
    "\n",
    "1. Model fitting: [`Model fitting - Replication.ipynb`](<../../notebooks/replication/Model fitting - Replication.ipynb>)\n",
    "2. Confidence analysis: [`Confidence analysis - Replication.ipynb`](<../../notebooks/replication/Confidence analysis - Replication.ipynb>)\n",
    "3. Two-step task analysis: [`Two-step modelling - Replication.ipynb`](<../../notebooks/replication/Two-step modelling - Replication.ipynb>)\n",
    "4. Transdiagnostic factor estimation: [`Transdiagnostic factors - Replication.ipynb`](<../../notebooks/replication/Transdiagnostic factors - Replication.ipynb>)\n",
    "5. Symptom-behaviour analyses: [`Symptom analyses - Replication.ipynb`](<../../notebooks/replication/Symptom analyses - Replication.ipynb>)\n",
    "\n",
    "#### Test-retest sample\n",
    "\n",
    "1. Model-fitting: [`Model fitting - Retest.ipynb`](<../../notebooks/retest/Model fitting - Retest.ipynb>)\n",
    "2. Two-step modelling: [`Two-step modelling - Retest.ipynb`](<../../notebooks/retest/Two-step modelling - Retest.ipynb>)\n",
    "3. Test-retest reliability analyses: [`Test-retest - Retest.ipynb`](<../../notebooks/retest/Test-retest - Retest.ipynb>)\n",
    "\n",
    "#### Follow-up sample\n",
    "\n",
    "1. **⭐ Model fitting: [`Model fitting - Follow up.ipynb`](<../../notebooks/follow-up/Model fitting - Follow up.ipynb>)** ⭐\n",
    "2. Transdiagnostic factor estimation: [`Transdiagnostic factors - Follow up.ipynb`](<../../notebooks/follow-up/Transdiagnostic factors - Follow up.ipynb>)\n",
    "3. Test-retest reliability analyses: [`Test-retest - Follow up.ipynb`](<../../notebooks/follow-up/Test-retest - Follow up.ipynb>)\n",
    "4. Longitudinal analyses: [`Longitudinal analyses - Follow up.ipynb`](<../../notebooks/follow-up/Longitudinal analyses - Follow up.ipynb>)\n",
    "\n",
    "#### Follow-up sample (1 year)\n",
    "\n",
    "1. Model fitting: [`Model fitting - Follow up 1yr.ipynb`](<../../notebooks/follow-up-1yr/Model fitting - Follow up 1yr.ipynb>)\n",
    "2. Transdiagnostic factor estimation: [`Transdiagnostic factors - Follow up 1yr.ipynb`](<../../notebooks/follow-up-1yr/Transdiagnostic factors - Follow up 1yr.ipynb>)\n",
    "3. Test-retest reliability analyses: [`Test-retest - Follow up 1yr.ipynb`](<../../notebooks/follow-up-1yr/Test-retest - Follow up 1yr.ipynb>)\n",
    "4. Longitudinal analyses: [`Longitudinal analyses -  Follow up 1yr.ipynb`](<../../notebooks/follow-up-1yr/Longitudinal analyses - Follow up 1yr.ipynb>)\n",
    "\n",
    "## Notebook overview\n",
    "\n",
    "This notebook performs model fitting using simulation-based inference with pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/user/miniconda3/envs/tu_test_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Font Heebo already available in Matplotlib.\n",
      "Matplotlib style set to: style.mplstyle with font Heebo\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/user/.local/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.3, the latest is 0.5.4.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from behavioural_modelling.learning.beta_models import beta_mean_var\n",
    "from model_fit_tools.plotting import *\n",
    "from model_fit_tools.plotting import plot_waic\n",
    "from scipy.stats import pearsonr\n",
    "from simulation_based_inference.npe import NPEModel\n",
    "\n",
    "from transition_uncertainty.modelling_utils import (\n",
    "    calculate_waic,\n",
    "    find_trained_models,\n",
    "    load_task_spec,\n",
    "    map_sampled_params,\n",
    "    repeat_for_all_subjects,\n",
    "    simulate_from_mean_params,\n",
    "    transform_to_bounded,\n",
    ")\n",
    "\n",
    "torch.set_num_threads(1)  # things are slow with multiple cores\n",
    "torch.set_num_interop_threads(1)  # things are slow with multiple cores\n",
    "from transition_uncertainty.style import set_style\n",
    "from transition_uncertainty.utils import check_directories\n",
    "\n",
    "# Raise an error if we're not in the root directory by checking if the data folder exists\n",
    "check_directories()\n",
    "\n",
    "# Set plotting style\n",
    "set_style(\"style.mplstyle\")\n",
    "\n",
    "# Report whether we're using GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load task specification\n",
    "\n",
    "Here we load in information about the task (e.g., rewards, transition probabilities, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load task specification\n",
    "(\n",
    "    second_stage_states,\n",
    "    second_stage_state_probs,\n",
    "    rewards,\n",
    "    reward_probs,\n",
    "    available_side,\n",
    ") = load_task_spec(\"data/task_spec\")\n",
    "\n",
    "# Get trials where MB was blocked\n",
    "MB_blocked = (reward_probs == 2)[0, :, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract choices from response data\n",
    "\n",
    "Next we need to load in the response data and extract the choices made by the participant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 412\n"
     ]
    }
   ],
   "source": [
    "choices = []\n",
    "\n",
    "data = pd.read_csv(\"data/follow-up/transition-task/cannonball_task_data.csv\")\n",
    "\n",
    "for sub in data[\"subjectID\"].unique():\n",
    "    choices.append(data[data[\"subjectID\"] == sub].response.values - 1)\n",
    "\n",
    "# Stack choices\n",
    "choices = np.stack(choices)[:, None, :]\n",
    "\n",
    "# Remove confidence trials as these are not relevant for model fitting\n",
    "choices_without_confidence = choices[:, :, available_side[0, :] == -1]\n",
    "\n",
    "# Get the number of subjects\n",
    "N_SUBJECTS = choices.shape[0]\n",
    "\n",
    "print(f\"Number of subjects: {N_SUBJECTS}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting using SBI\n",
    "\n",
    "Parameters are estimated using simulation-based inference. We use the models that were pre-trained using the scripts provided in the `./scripts` directory.\n",
    "\n",
    "Here we only fit the pure model-based model as this was the winning model at the initial time point.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in trained models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify models\n",
    "models = [\"mf_only\", \"mb_only\"]\n",
    "\n",
    "# Get the trained models\n",
    "trained_models = find_trained_models(models, \"models\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the posterior\n",
    "\n",
    "This seems to work slowly if you don't have a lot of memory...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling parameters for model: mf_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                      | 0/412 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 412/412 [00:14<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling parameters for model: mb_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 412/412 [00:14<00:00, 29.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through models and sample parameters\n",
    "sampled_params_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    print(\"Sampling parameters for model: {}\".format(model))\n",
    "    sampled_params_dict[model] = trained_models[model].sample(\n",
    "        choices_without_confidence, n_samples=1000\n",
    "    )\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(\"results/follow-up/transition-task_model-fit\"):\n",
    "    os.makedirs(\"results/follow-up/transition-task_model-fit\")\n",
    "\n",
    "# Save the sampled parameters\n",
    "with open(\n",
    "    os.path.join(\n",
    "        \"results/follow-up/transition-task_model-fit\",\n",
    "        \"sampled_params_dict.pkl\",\n",
    "    ),\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    dill.dump(sampled_params_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit\n",
    "\n",
    "Next we estimate the [WAIC](https://arxiv.org/abs/1507.04544) for each model. This is a measure of model fit that penalises models with more parameters. We use the [arviz](https://arviz-devs.github.io/arviz/) package to calculate the WAIC, both across all subjects and for each subject individually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating WAIC for model: mf_only\n",
      "Calculating WAIC for model: mb_only\n"
     ]
    }
   ],
   "source": [
    "# Initialise dictionaries\n",
    "waic_dict = {}\n",
    "subject_waic_dict = {}\n",
    "\n",
    "# Loop through models and calculate WAIC\n",
    "for model in models:\n",
    "    print(\"Calculating WAIC for model: {}\".format(model))\n",
    "\n",
    "    # Create a template array to fill in with estimated parameters Different\n",
    "    # models have different numbers of parameters, but the WAIC function\n",
    "    # requires that all models have the same number of parameters. This\n",
    "    # template array is used to fill in the estimated parameters for each\n",
    "    # model.\n",
    "    sampled_param_template = np.zeros(\n",
    "        (\n",
    "            sampled_params_dict[model].shape[0],\n",
    "            sampled_params_dict[model].shape[1],\n",
    "            6,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Map sampled parameters to the template array\n",
    "    sampled_params_mapped = map_sampled_params(\n",
    "        model, sampled_params_dict[model], sampled_param_template\n",
    "    )\n",
    "\n",
    "    # Transform back to bounded\n",
    "    sampled_params_mapped[:, :, 4] = transform_to_bounded(\n",
    "        sampled_params_mapped[:, :, 4], 0.1, 0.9\n",
    "    )\n",
    "    sampled_params_mapped[:, :, 5] = transform_to_bounded(\n",
    "        sampled_params_mapped[:, :, 5], 0.01, 0.2\n",
    "    )\n",
    "\n",
    "    # Get dataset and waic\n",
    "    ds, waic_dict[model] = calculate_waic(\n",
    "        sampled_params_mapped,\n",
    "        second_stage_states,\n",
    "        rewards,\n",
    "        reward_probs,\n",
    "        available_side,\n",
    "        choices,\n",
    "        pointwise=True,\n",
    "    )\n",
    "\n",
    "    # Get subject-wise WAIC\n",
    "    subject_waic_dict[model] = waic_dict[model].waic_i.sum(axis=-1)\n",
    "\n",
    "########################\n",
    "# Convert to dataframe #\n",
    "########################\n",
    "\n",
    "# Initialise dataframe\n",
    "waic_df = {\"model\": [], \"waic\": [], \"se\": []}\n",
    "\n",
    "# Loop through models and append values to dataframe\n",
    "for model, waic in waic_dict.items():\n",
    "    waic_df[\"model\"].append(model)\n",
    "    waic_df[\"waic\"].append(waic.elpd_waic)\n",
    "    waic_df[\"se\"].append(waic.se)\n",
    "\n",
    "# Convert to dataframe\n",
    "waic_df = pd.DataFrame(waic_df)\n",
    "waic_df.head()\n",
    "\n",
    "# Get unique subject IDs\n",
    "unique_subject_IDs = pd.Series(data[\"subjectID\"].unique())\n",
    "\n",
    "# Convert your original dictionary to a DataFrame\n",
    "subject_waic_df = pd.DataFrame(subject_waic_dict).stack().reset_index()\n",
    "\n",
    "# Assign proper column names\n",
    "subject_waic_df.columns = [\"subject\", \"model\", \"waic\"]\n",
    "\n",
    "# Ensure that 'subject' column has corresponding subject IDs\n",
    "subject_waic_df[\"subject\"] = unique_subject_IDs.loc[\n",
    "    subject_waic_df[\"subject\"]\n",
    "].values\n",
    "\n",
    "# Save dataframes\n",
    "waic_df.to_csv(\"results/follow-up/transition-task_model-fit/group_waic.csv\")\n",
    "subject_waic_df.to_csv(\n",
    "    \"results/follow-up/transition-task_model-fit/subject_waic.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot estimated parameter distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 559.92x224 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_names = [\n",
    "    \"$\\\\tau_p$\",\n",
    "    \"$\\\\lambda_p$\",\n",
    "    \"Temperature\",\n",
    "]\n",
    "\n",
    "plot_parameter_dists(sampled_params_dict[\"mb_only\"], param_names=param_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add parameter values to a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectID</th>\n",
       "      <th>tau_value</th>\n",
       "      <th>tau_prob</th>\n",
       "      <th>decay_value</th>\n",
       "      <th>decay_prob</th>\n",
       "      <th>W</th>\n",
       "      <th>temperature</th>\n",
       "      <th>MB_MF_WAIC_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.607175</td>\n",
       "      <td>0.449443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515616</td>\n",
       "      <td>16.962467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651357</td>\n",
       "      <td>0.251545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.671629</td>\n",
       "      <td>12.398017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.649393</td>\n",
       "      <td>-0.525352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subjectID  tau_value  tau_prob  decay_value  decay_prob    W  temperature  \\\n",
       "0   sub-001        0.0  0.045253          0.0    0.549014  1.0     0.607175   \n",
       "1   sub-002        0.0  0.495104          0.0    0.560250  1.0     0.515616   \n",
       "2   sub-003        0.0  0.035006          0.0    0.388169  1.0     0.651357   \n",
       "3   sub-004        0.0  0.425840          0.0    0.540624  1.0     0.671629   \n",
       "4   sub-005        0.0  0.089469          0.0    0.534215  1.0     0.649393   \n",
       "\n",
       "   MB_MF_WAIC_diff  \n",
       "0         0.449443  \n",
       "1        16.962467  \n",
       "2         0.251545  \n",
       "3        12.398017  \n",
       "4        -0.525352  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = \"mb_only\"\n",
    "\n",
    "best_model_sampled_params = sampled_params_dict[best_model].copy()\n",
    "\n",
    "# Fill in the template array\n",
    "sampled_param_template = np.zeros(\n",
    "    (best_model_sampled_params.shape[0], best_model_sampled_params.shape[1], 6)\n",
    ")\n",
    "\n",
    "# Map sampled parameters to the template array\n",
    "best_model_sampled_params = map_sampled_params(\n",
    "    best_model, best_model_sampled_params, sampled_param_template\n",
    ").mean(axis=0)\n",
    "\n",
    "param_df = {\n",
    "    \"subjectID\": data[\"subjectID\"].unique(),\n",
    "    \"tau_value\": best_model_sampled_params[:, 0],\n",
    "    \"tau_prob\": best_model_sampled_params[:, 1],\n",
    "    \"decay_value\": best_model_sampled_params[:, 2],\n",
    "    \"decay_prob\": best_model_sampled_params[:, 3],\n",
    "    \"W\": best_model_sampled_params[:, 4],\n",
    "    \"temperature\": best_model_sampled_params[:, 5],\n",
    "    \"MB_MF_WAIC_diff\": (\n",
    "        subject_waic_dict[\"mb_only\"] - subject_waic_dict[\"mf_only\"]\n",
    "    ).data,\n",
    "}\n",
    "\n",
    "param_df = pd.DataFrame(param_df)\n",
    "\n",
    "param_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data using estimated parameters\n",
    "\n",
    "This code simulates data from the winning model using the estimated parameters.\n",
    "\n",
    "This creates two `.csv` files:\n",
    "\n",
    "-   `data/task/model_fit_results/param_df.csv`: This contains the estimated parameter values for each subject, alongside the average mean and variance of transition estimates across the task for each subject.\n",
    "-   `data/task/model_fit_results/cannonball_task_data_with_model_values.csv`: This augments the raw task data for each subject with trialwise estimates of the mean and variance of transition estiamtes across the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data from the model using the mean parameter values\n",
    "_, transition_estimates, combined_dists = simulate_from_mean_params(\n",
    "    best_model_sampled_params,\n",
    "    second_stage_states,\n",
    "    rewards,\n",
    "    reward_probs,\n",
    "    available_side,\n",
    ")\n",
    "\n",
    "# Get average transition mean and var across the task\n",
    "transition_mean, transition_var = beta_mean_var(transition_estimates)\n",
    "param_df[\"transition_mean\"] = transition_mean.squeeze().mean(axis=1)\n",
    "param_df[\"transition_var\"] = transition_var.squeeze().mean(axis=1)\n",
    "\n",
    "# Get average combined mean and var across the task\n",
    "combined_mean, combined_var = beta_mean_var(combined_dists)\n",
    "param_df[\"combined_mean\"] = combined_mean.squeeze().mean(axis=-1).mean(axis=-1)\n",
    "param_df[\"combined_var\"] = combined_var.squeeze().mean(axis=-1).mean(axis=-1)\n",
    "\n",
    "# Save\n",
    "param_df.to_csv(\n",
    "    \"results/follow-up/transition-task_model-fit/param_df.csv\", index=False\n",
    ")\n",
    "\n",
    "# Get transition mean and var at each trial\n",
    "transition_mean = transition_mean.flatten()\n",
    "transition_var = transition_var.flatten()\n",
    "\n",
    "# Add mean and var to data\n",
    "data[\"transition_mean\"] = transition_mean\n",
    "data[\"transition_var\"] = transition_var\n",
    "\n",
    "# Save\n",
    "data.to_csv(\n",
    "    \"results/follow-up/transition-task_model-fit/cannonball_task_data_with_model_values.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tu_test_env",
   "language": "python",
   "name": "tu_test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
