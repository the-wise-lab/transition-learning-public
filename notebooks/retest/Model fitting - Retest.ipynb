{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting - Retest Sample\n",
    "\n",
    "## Analysis overview\n",
    "\n",
    "#### Discovery sample\n",
    "\n",
    "1. Model fitting: [`Model fitting - Discovery.ipynb`](<../../notebooks/discovery/Model fitting - Discovery.ipynb>)\n",
    "2. Confidence analysis: [`Confidence analysis - Discovery.ipynb`](<../../notebooks/discovery/Confidence analysis - Discovery.ipynb>)\n",
    "3. Transdiagnostic factor estimation: [`Transdiagnostic factors - Discovery.ipynb`](<../../notebooks/discovery/Transdiagnostic factors - Discovery.ipynb>)\n",
    "4. Symptom-behaviour analyses: [`Symptom analyses - Discovery.ipynb`](<../../notebooks/discovery/Symptom analyses - Discovery.ipynb>)\n",
    "\n",
    "#### Replication sample\n",
    "\n",
    "1. Model fitting: [`Model fitting - Replication.ipynb`](<../../notebooks/replication/Model fitting - Replication.ipynb>)\n",
    "2. Confidence analysis: [`Confidence analysis - Replication.ipynb`](<../../notebooks/replication/Confidence analysis - Replication.ipynb>)\n",
    "3. Two-step task analysis: [`Two-step modelling - Replication.ipynb`](<../../notebooks/replication/Two-step modelling - Replication.ipynb>)\n",
    "4. Transdiagnostic factor estimation: [`Transdiagnostic factors - Replication.ipynb`](<../../notebooks/replication/Transdiagnostic factors - Replication.ipynb>)\n",
    "5. Symptom-behaviour analyses: [`Symptom analyses - Replication.ipynb`](<../../notebooks/replication/Symptom analyses - Replication.ipynb>)\n",
    "\n",
    "#### Test-retest sample\n",
    "\n",
    "1. **⭐ Model-fitting: [`Model fitting - Retest.ipynb`](<../../notebooks/retest/Model fitting - Retest.ipynb>)** ⭐\n",
    "2. Two-step modelling: [`Two-step modelling - Retest.ipynb`](<../../notebooks/retest/Two-step modelling - Retest.ipynb>)\n",
    "3. Test-retest reliability analyses: [`Test-retest - Retest.ipynb`](<../../notebooks/retest/Test-retest - Retest.ipynb>)\n",
    "\n",
    "#### Follow-up sample\n",
    "\n",
    "1. Model fitting: [`Model fitting - Follow up.ipynb`](<../../notebooks/follow-up/Model fitting - Follow up.ipynb>)\n",
    "2. Transdiagnostic factor estimation: [`Transdiagnostic factors - Follow up.ipynb`](<../../notebooks/follow-up/Transdiagnostic factors - Follow up.ipynb>)\n",
    "3. Test-retest reliability analyses: [`Test-retest - Follow up.ipynb`](<../../notebooks/follow-up/Test-retest - Follow up.ipynb>)\n",
    "4. Longitudinal analyses: [`Longitudinal analyses - Follow up.ipynb`](<../../notebooks/follow-up/Longitudinal analyses - Follow up.ipynb>)\n",
    "\n",
    "#### Follow-up sample (1 year)\n",
    "\n",
    "1. Model fitting: [`Model fitting - Follow up 1yr.ipynb`](<../../notebooks/follow-up-1yr/Model fitting - Follow up 1yr.ipynb>)\n",
    "2. Transdiagnostic factor estimation: [`Transdiagnostic factors - Follow up 1yr.ipynb`](<../../notebooks/follow-up-1yr/Transdiagnostic factors - Follow up 1yr.ipynb>)\n",
    "3. Test-retest reliability analyses: [`Test-retest - Follow up 1yr.ipynb`](<../../notebooks/follow-up-1yr/Test-retest - Follow up 1yr.ipynb>)\n",
    "4. Longitudinal analyses: [`Longitudinal analyses -  Follow up 1yr.ipynb`](<../../notebooks/follow-up-1yr/Longitudinal analyses - Follow up 1yr.ipynb>)\n",
    "\n",
    "## Notebook overview\n",
    "\n",
    "This notebook performs model fitting using simulation-based inference with pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/user/miniconda3/envs/tu_test_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Font Heebo already available in Matplotlib.\n",
      "Matplotlib style set to: style.mplstyle with font Heebo\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from behavioural_modelling.learning.beta_models import beta_mean_var\n",
    "from model_fit_tools.plotting import *\n",
    "from model_fit_tools.plotting import plot_waic\n",
    "from scipy.stats import pearsonr\n",
    "from simulation_based_inference.npe import NPEModel\n",
    "\n",
    "from transition_uncertainty.modelling_utils import (\n",
    "    calculate_waic,\n",
    "    find_trained_models,\n",
    "    load_task_spec,\n",
    "    map_sampled_params,\n",
    "    repeat_for_all_subjects,\n",
    "    simulate_from_mean_params,\n",
    "    transform_to_bounded,\n",
    ")\n",
    "\n",
    "torch.set_num_threads(1)  # things are slow with multiple cores\n",
    "torch.set_num_interop_threads(1)  # things are slow with multiple cores\n",
    "from transition_uncertainty.style import set_style\n",
    "from transition_uncertainty.utils import check_directories\n",
    "\n",
    "# Raise an error if we're not in the root directory by checking if the data folder exists\n",
    "check_directories()\n",
    "\n",
    "# Set plotting style\n",
    "set_style(\"style.mplstyle\")\n",
    "\n",
    "# Report whether we're using GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load task specification\n",
    "\n",
    "Here we load in information about the task (e.g., rewards, transition probabilities, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/user/.local/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.3, the latest is 0.5.4.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "# Load task specification\n",
    "(\n",
    "    second_stage_states,\n",
    "    second_stage_state_probs,\n",
    "    rewards,\n",
    "    reward_probs,\n",
    "    available_side,\n",
    ") = load_task_spec(\"data/task_spec\")\n",
    "\n",
    "# Get trials where MB was blocked\n",
    "MB_blocked = (reward_probs == 2)[0, :, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract choices from response data\n",
    "\n",
    "Next we need to load in the response data and extract the choices made by the participant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 85\n"
     ]
    }
   ],
   "source": [
    "choices = []\n",
    "\n",
    "data = pd.read_csv(\"data/retest/transition-task/cannonball_task_data.csv\")\n",
    "\n",
    "for sub in data[\"subjectID\"].unique():\n",
    "    choices.append(data[data[\"subjectID\"] == sub].response.values - 1)\n",
    "\n",
    "# Stack choices\n",
    "choices = np.stack(choices)[:, None, :]\n",
    "\n",
    "# Remove confidence trials as these are not relevant for model fitting\n",
    "choices_without_confidence = choices[:, :, available_side[0, :] == -1]\n",
    "\n",
    "# Get the number of subjects\n",
    "N_SUBJECTS = choices.shape[0]\n",
    "\n",
    "print(f\"Number of subjects: {N_SUBJECTS}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting using SBI\n",
    "\n",
    "Parameters are estimated using simulation-based inference. We use the models that were pre-trained using the scripts provided in the `./scripts` directory.\n",
    "\n",
    "Here we only fit the pure model-based model as this was the winning model at the initial time point.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in trained models\n",
    "\n",
    "We don't care about the combination models here as they didn't fit well, so we only load the best-fitting model (pure model-based), along with the pure model-free model to provide measures of model-basedness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify models\n",
    "models = [\"mf_only\", \"mb_only\"]\n",
    "\n",
    "# Get the trained models\n",
    "trained_models = find_trained_models(models, \"models\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the posterior\n",
    "\n",
    "This seems to work slowly if you don't have a lot of memory...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling parameters for model: mf_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 85/85 [00:02<00:00, 28.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling parameters for model: mb_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 85/85 [00:02<00:00, 29.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through models and sample parameters\n",
    "sampled_params_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    print(\"Sampling parameters for model: {}\".format(model))\n",
    "    sampled_params_dict[model] = trained_models[model].sample(\n",
    "        choices_without_confidence, n_samples=1000\n",
    "    )\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(\"results/retest/transition-task_model-fit\"):\n",
    "    os.makedirs(\"results/retest/transition-task_model-fit\")\n",
    "\n",
    "# Save the sampled parameters\n",
    "with open(\n",
    "    os.path.join(\n",
    "        \"results/retest/transition-task_model-fit\", \"sampled_params_dict.pkl\"\n",
    "    ),\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    dill.dump(sampled_params_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit\n",
    "\n",
    "Next we estimate the [WAIC](https://arxiv.org/abs/1507.04544) for each model. This is a measure of model fit that penalises models with more parameters. We use the [arviz](https://arviz-devs.github.io/arviz/) package to calculate the WAIC, both across all subjects and for each subject individually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating WAIC for model: mf_only\n",
      "Calculating WAIC for model: mb_only\n"
     ]
    }
   ],
   "source": [
    "# Initialise dictionaries\n",
    "waic_dict = {}\n",
    "subject_waic_dict = {}\n",
    "\n",
    "# Loop through models and calculate WAIC\n",
    "for model in models:\n",
    "    print(\"Calculating WAIC for model: {}\".format(model))\n",
    "\n",
    "    # Create a template array to fill in with estimated parameters Different\n",
    "    # models have different numbers of parameters, but the WAIC function\n",
    "    # requires that all models have the same number of parameters. This\n",
    "    # template array is used to fill in the estimated parameters for each\n",
    "    # model.\n",
    "    sampled_param_template = np.zeros(\n",
    "        (\n",
    "            sampled_params_dict[model].shape[0],\n",
    "            sampled_params_dict[model].shape[1],\n",
    "            6,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Map sampled parameters to the template array\n",
    "    sampled_params_mapped = map_sampled_params(\n",
    "        model, sampled_params_dict[model], sampled_param_template\n",
    "    )\n",
    "\n",
    "    # Transform back to bounded\n",
    "    sampled_params_mapped[:, :, 4] = transform_to_bounded(\n",
    "        sampled_params_mapped[:, :, 4], 0.1, 0.9\n",
    "    )\n",
    "    sampled_params_mapped[:, :, 5] = transform_to_bounded(\n",
    "        sampled_params_mapped[:, :, 5], 0.01, 0.2\n",
    "    )\n",
    "\n",
    "    # Get dataset and waic\n",
    "    ds, waic_dict[model] = calculate_waic(\n",
    "        sampled_params_mapped,\n",
    "        second_stage_states,\n",
    "        rewards,\n",
    "        reward_probs,\n",
    "        available_side,\n",
    "        choices,\n",
    "        pointwise=True,\n",
    "    )\n",
    "\n",
    "    # Get subject-wise WAIC\n",
    "    subject_waic_dict[model] = waic_dict[model].waic_i.sum(axis=-1)\n",
    "\n",
    "########################\n",
    "# Convert to dataframe #\n",
    "########################\n",
    "\n",
    "# Initialise dataframe\n",
    "waic_df = {\"model\": [], \"waic\": [], \"se\": []}\n",
    "\n",
    "# Loop through models and append values to dataframe\n",
    "for model, waic in waic_dict.items():\n",
    "    waic_df[\"model\"].append(model)\n",
    "    waic_df[\"waic\"].append(waic.elpd_waic)\n",
    "    waic_df[\"se\"].append(waic.se)\n",
    "\n",
    "# Convert to dataframe\n",
    "waic_df = pd.DataFrame(waic_df)\n",
    "waic_df.head()\n",
    "\n",
    "# Get unique subject IDs\n",
    "unique_subject_IDs = pd.Series(data[\"subjectID\"].unique())\n",
    "\n",
    "# Convert your original dictionary to a DataFrame\n",
    "subject_waic_df = pd.DataFrame(subject_waic_dict).stack().reset_index()\n",
    "\n",
    "# Assign proper column names\n",
    "subject_waic_df.columns = [\"subject\", \"model\", \"waic\"]\n",
    "\n",
    "# Ensure that 'subject' column has corresponding subject IDs\n",
    "subject_waic_df[\"subject\"] = unique_subject_IDs.loc[\n",
    "    subject_waic_df[\"subject\"]\n",
    "].values\n",
    "\n",
    "# Save dataframes\n",
    "waic_df.to_csv(\"results/retest/transition-task_model-fit/group_waic.csv\")\n",
    "subject_waic_df.to_csv(\n",
    "    \"results/retest/transition-task_model-fit/subject_waic.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot estimated parameter distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 559.92x224 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_names = [\n",
    "    \"$\\\\tau_p$\",\n",
    "    \"$\\\\lambda_p$\",\n",
    "    \"Temperature\",\n",
    "]\n",
    "\n",
    "plot_parameter_dists(sampled_params_dict[\"mb_only\"], param_names=param_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add parameter values to a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectID</th>\n",
       "      <th>tau_value</th>\n",
       "      <th>tau_prob</th>\n",
       "      <th>decay_value</th>\n",
       "      <th>decay_prob</th>\n",
       "      <th>W</th>\n",
       "      <th>temperature</th>\n",
       "      <th>MB_MF_WAIC_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650153</td>\n",
       "      <td>1.512692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666448</td>\n",
       "      <td>0.236178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.069525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.657942</td>\n",
       "      <td>14.284002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-1032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632648</td>\n",
       "      <td>-1.138342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subjectID  tau_value  tau_prob  decay_value  decay_prob    W  temperature  \\\n",
       "0   sub-008        0.0  0.074443          0.0    0.393051  1.0     0.650153   \n",
       "1   sub-024        0.0  0.096424          0.0    0.267478  1.0     0.666448   \n",
       "2   sub-069        0.0  0.144345          0.0    0.614619  1.0     0.697329   \n",
       "3   sub-100        0.0  0.473795          0.0    0.679079  1.0     0.657942   \n",
       "4  sub-1032        0.0  0.059271          0.0    0.468900  1.0     0.632648   \n",
       "\n",
       "   MB_MF_WAIC_diff  \n",
       "0         1.512692  \n",
       "1         0.236178  \n",
       "2         0.069525  \n",
       "3        14.284002  \n",
       "4        -1.138342  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = \"mb_only\"\n",
    "\n",
    "best_model_sampled_params = sampled_params_dict[best_model].copy()\n",
    "\n",
    "# Fill in the template array\n",
    "sampled_param_template = np.zeros(\n",
    "    (best_model_sampled_params.shape[0], best_model_sampled_params.shape[1], 6)\n",
    ")\n",
    "\n",
    "# Map sampled parameters to the template array\n",
    "best_model_sampled_params = map_sampled_params(\n",
    "    best_model, best_model_sampled_params, sampled_param_template\n",
    ").mean(axis=0)\n",
    "\n",
    "param_df = {\n",
    "    \"subjectID\": data[\"subjectID\"].unique(),\n",
    "    \"tau_value\": best_model_sampled_params[:, 0],\n",
    "    \"tau_prob\": best_model_sampled_params[:, 1],\n",
    "    \"decay_value\": best_model_sampled_params[:, 2],\n",
    "    \"decay_prob\": best_model_sampled_params[:, 3],\n",
    "    \"W\": best_model_sampled_params[:, 4],\n",
    "    \"temperature\": best_model_sampled_params[:, 5],\n",
    "    \"MB_MF_WAIC_diff\": (\n",
    "        subject_waic_dict[\"mb_only\"] - subject_waic_dict[\"mf_only\"]\n",
    "    ).data,\n",
    "}\n",
    "\n",
    "param_df = pd.DataFrame(param_df)\n",
    "\n",
    "param_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data using estimated parameters\n",
    "\n",
    "This code simulates data from the winning model using the estimated parameters.\n",
    "\n",
    "This creates two `.csv` files:\n",
    "\n",
    "-   `data/task/model_fit_results/param_df.csv`: This contains the estimated parameter values for each subject, alongside the average mean and variance of transition estimates across the task for each subject.\n",
    "-   `data/task/model_fit_results/cannonball_task_data_with_model_values.csv`: This augments the raw task data for each subject with trialwise estimates of the mean and variance of transition estiamtes across the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data from the model using the mean parameter values\n",
    "_, transition_estimates, combined_dists = simulate_from_mean_params(\n",
    "    best_model_sampled_params,\n",
    "    second_stage_states,\n",
    "    rewards,\n",
    "    reward_probs,\n",
    "    available_side,\n",
    ")\n",
    "\n",
    "# Get average transition mean and var across the task\n",
    "transition_mean, transition_var = beta_mean_var(transition_estimates)\n",
    "param_df[\"transition_mean\"] = transition_mean.squeeze().mean(axis=1)\n",
    "param_df[\"transition_var\"] = transition_var.squeeze().mean(axis=1)\n",
    "\n",
    "# Get average combined mean and var across the task\n",
    "combined_mean, combined_var = beta_mean_var(combined_dists)\n",
    "param_df[\"combined_mean\"] = combined_mean.squeeze().mean(axis=-1).mean(axis=-1)\n",
    "param_df[\"combined_var\"] = combined_var.squeeze().mean(axis=-1).mean(axis=-1)\n",
    "\n",
    "# Save\n",
    "param_df.to_csv(\n",
    "    \"results/retest/transition-task_model-fit/param_df.csv\", index=False\n",
    ")\n",
    "\n",
    "# Get transition mean and var at each trial\n",
    "transition_mean = transition_mean.flatten()\n",
    "transition_var = transition_var.flatten()\n",
    "\n",
    "# Add mean and var to data\n",
    "data[\"transition_mean\"] = transition_mean\n",
    "data[\"transition_var\"] = transition_var\n",
    "\n",
    "# Save\n",
    "data.to_csv(\n",
    "    \"results/retest/transition-task_model-fit/cannonball_task_data_with_model_values.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tu_test_env",
   "language": "python",
   "name": "tu_test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
